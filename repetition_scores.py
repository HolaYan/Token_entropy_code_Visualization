import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, Qwen2_5_VLForConditionalGeneration, AutoProcessor
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Rectangle
from collections import defaultdict
import re
import os
from matplotlib.colors import LinearSegmentedColormap

# Set cache directories
os.environ["TRANSFORMERS_CACHE"] = "/gpfs/scratch/lh3862/project/VLLMreasoning/Model"
os.environ["HF_HOME"] = "/gpfs/scratch/lh3862/project/VLLMreasoning/Model"

# ğŸ”¥ æ–°å¢ï¼šç®€å•çš„activationæ”¶é›†å™¨
def setup_activation_hooks(model, pattern=r"model\.layers\.\d+\.mlp$"):
    """ä¸€è¡Œä»£ç è®¾ç½®activation hooks"""
    activities = defaultdict(list)
    hooks = []
    
    def mlp_hook_fn(module, input, output):
        last_token_act = output[:, -1, :]  # shape: [1, hidden_dim]
        activities[module._hook_name].append(last_token_act.detach().cpu())
    
    # Setup MLP hooks
    compiled_mlp_pattern = re.compile(pattern)
    for name, module in model.named_modules():
        if compiled_mlp_pattern.match(name):
            module._hook_name = name
            hooks.append(module.register_forward_hook(mlp_hook_fn))
    
    return activities, hooks

def clean_hooks(hooks):
    """æ¸…ç†hooks"""
    for h in hooks:
        h.remove()

def analyze_token_entropy(model, tokenizer, text, max_new_tokens=10, collect_activations=False):
    """åˆ†æç”Ÿæˆtokençš„ç†µå€¼ + å¯é€‰çš„activationæ”¶é›† + logitsæ”¶é›†"""
    
    # ğŸ”¥ æ–°å¢ï¼šå¯é€‰çš„activationæ”¶é›†
    activities, hooks = None, []
    if collect_activations:
        activities, hooks = setup_activation_hooks(model)
        activities.clear()
    
    # ç¼–ç è¾“å…¥
    inputs = tokenizer(text=text, return_tensors="pt").to(model.device)
    
    # æ­£å¸¸è¾“å‡ºæ¨¡å¼
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            do_sample=False,
            pad_token_id=tokenizer.eos_token_id
        )
    responses = tokenizer.batch_decode(outputs, skip_special_tokens=True)
    print(f"ç”Ÿæˆçš„å“åº”: {responses[0]}")
    print(f"è¾“å…¥æ–‡æœ¬: {text}")

    # ç”Ÿæˆå¹¶è·å–scores
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            do_sample=False,
            output_scores=True,
            output_attentions=True,
            return_dict_in_generate=True,
            pad_token_id=tokenizer.eos_token_id
        )
    
    # æå–ç”Ÿæˆçš„tokenså’Œscores
    prompt_len = inputs['input_ids'].shape[1]
    gen_tokens = outputs.sequences[0][prompt_len:]
    scores = outputs.scores
    
    # ç¡®ä¿é•¿åº¦ä¸€è‡´
    min_len = min(len(scores), len(gen_tokens))
    
    # è®¡ç®—ç†µå€¼å’Œtokenå­—ç¬¦ä¸²
    tokens = []
    entropies = []
    # ğŸ”¥ æ–°å¢ï¼šä¿å­˜logitsç”¨äºåˆ†å¸ƒå¯è§†åŒ–
    all_logits = []
    
    for i in range(min_len):
        # è·å–å½“å‰æ­¥éª¤çš„logits
        logits = scores[i][0].cpu()  # [vocab_size]
        all_logits.append(logits)
        
        # è®¡ç®—ç†µ
        probs = torch.softmax(logits, dim=-1)
        entropy = -torch.sum(probs * torch.log(probs + 1e-12)).item()
        entropies.append(entropy)
        
        # è·å–tokenå­—ç¬¦ä¸²
        token = tokenizer.decode([gen_tokens[i]], skip_special_tokens=False)
        tokens.append(token)
    
    # ğŸ”¥ æ–°å¢ï¼šå¤„ç†activations
    activations = None
    if collect_activations and activities:
        activations = {}
        for layer, acts in activities.items():
            # å¤„ç†MLP activations
            layer_acts = torch.cat(acts, dim=0)  # shape: [num_generated_tokens, hidden_dim]
            activations[layer] = layer_acts.cpu().float()
            
        clean_hooks(hooks)  # æ¸…ç†
    
    # ğŸ”¥ å¤„ç†attentionæ•°æ®
    if hasattr(outputs, 'attentions') and outputs.attentions:
        num_layers = len(outputs.attentions[0])  # å±‚æ•°
        num_heads = outputs.attentions[0][0].shape[1]  # headæ•°
        all_attn_matrices = {}

        for layer_idx in range(num_layers):
            for head_idx in range(num_heads):
                # layer_idx = 63   # å“ªä¸€å±‚
                # head_idx = 7    # å“ªä¸ªhead

                attn_vectors = []
                lengths = []

                # éå†æ¯ä¸ªç”Ÿæˆæ­¥
                for i, step_attn in enumerate(outputs.attentions):
                    # step_attn: tuple of all layers
                    attn_tensor = step_attn[layer_idx]  # shape: [1, num_heads, 1, key_len]
                    # å–batch=0, head=head_idx, query=0
                    vec = attn_tensor[0, head_idx, 0, :]  # shape: [key_len]
                    attn_vectors.append(vec)
                    lengths.append(vec.shape[0])

                max_len = max(lengths)
                # padæ¯ä¸ªå‘é‡åˆ° max_len
                padded_vectors = []
                for vec in attn_vectors:
                    pad_size = max_len - vec.shape[0]
                    padded = torch.nn.functional.pad(vec, (0, pad_size), value=0)
                    padded_vectors.append(padded)
                # å †å æˆçŸ©é˜µ
                attn_matrix = torch.stack(padded_vectors, dim=0)  
                all_attn_matrices[f'layer_{layer_idx}_head_{head_idx}'] = attn_matrix
        # import pdb;pdb.set_trace()
        print("Padded attention matrix shape:", attn_matrix.shape)

    return tokens, entropies, activations, all_attn_matrices, all_logits

def compute_token_scores(tokens, entropies, activations, logits, attn_matrix, alpha=1.0, beta=1.0, delta=1.0):
    """
    è®¡ç®—æ¯ä¸ªtokençš„å››ä¸ªæŒ‡æ ‡å’Œæœ€ç»ˆç»„åˆscore
    """
    V = logits[0].size(0)
    max_token_entropy = np.log(V)

    # TokenEntropy
    token_entropy_norm = [e / max_token_entropy for e in entropies]

    # ActivationRise
    # å‡è®¾activationsæ˜¯ Dict[layer -> Tensor[num_tokens, hidden_dim]]
    layer_name = list(activations.keys())[-1]
    acts = activations[layer_name]  # shape: [num_tokens, hidden_dim]
    norms = acts.norm(p=2, dim=-1)
    activation_rises = [0.0] + [(norms[i] - norms[i-1]).item() for i in range(1, len(norms))]
    min_act, max_act = min(activation_rises), max(activation_rises)
    activation_rise_norm = [(v - min_act) / (max_act - min_act + 1e-6) for v in activation_rises]

    # Uniformity
    uniformities = []
    log_uniform_prob = -np.log(V)
    for l in logits:
        probs = torch.softmax(l, dim=-1)
        log_probs = torch.log(probs + 1e-12)
        kl_div = (probs * (log_probs - log_uniform_prob)).sum().item()
        uniformity = 1 - kl_div
        uniformities.append(np.clip(uniformity,0,1))

    # Attention Focus
    max_attn_entropy = np.log(attn_matrix.size(1))
    attn_entropies = []
    for row in attn_matrix:
        norm_row = row / (row.sum() + 1e-12)
        entropy = -(norm_row * torch.log(norm_row + 1e-12)).sum().item()
        attn_entropies.append(entropy)
    attn_focus = [1 - (e / max_attn_entropy) for e in attn_entropies]

    # Final Score
    scores = []
    for i in range(len(tokens)):
        s = (
            token_entropy_norm[i]
            + alpha * activation_rise_norm[i]
            + beta * uniformities[i]
            + delta * attn_focus[i]
        )
        scores.append(s)

    # æ‰“åŒ…è¿”å›
    result = {
        "tokens": tokens,
        "TokenEntropy": token_entropy_norm,
        "ActivationRise": activation_rise_norm,
        "Uniformity": uniformities,
        "AttentionFocus": attn_focus,
        "FinalScore": scores
    }
    return result

def plot_token_scores(score_dict):
    """
    ç»˜åˆ¶æ¯ä¸ªtokençš„æŒ‡æ ‡å’Œæœ€ç»ˆscore
    """
    tokens = score_dict["tokens"]
    x = list(range(len(tokens)))
    fig, ax = plt.subplots(figsize=(14,5))

    ax.plot(x, score_dict["TokenEntropy"], label="TokenEntropy")
    ax.plot(x, score_dict["ActivationRise"], label="ActivationRise")
    ax.plot(x, score_dict["Uniformity"], label="Uniformity")
    ax.plot(x, score_dict["AttentionFocus"], label="AttentionFocus")
    ax.plot(x, score_dict["FinalScore"], label="FinalScore", linewidth=2, color="black")

    ax.set_xticks(x)
    ax.set_xticklabels(tokens, rotation=90, fontsize=8)
    ax.set_xlabel("Generated Tokens")
    ax.set_ylabel("Normalized Scores")
    ax.set_title("Per-token Indicators and Final Score")
    ax.legend()
    plt.tight_layout()
    plt.show()
    

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åŠ è½½æ¨¡å‹
    # model_path = "Qwen/Qwen2.5-32B-Instruct"
    model_path = "Qwen/Qwen2.5-7B"
    dir_path = "/gpfs/scratch/lh3862/project/VLLMreasoning/Model"
    
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        # attn_implementation="flash_attention_2",
        attn_implementation="eager",
        device_map="auto",
        cache_dir=dir_path,
    )
    
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
    )

    # åˆ†ææ–‡æœ¬ Find all c in Z_3 such that Z_3[x]\/(x^2 + c) is a field.\n\n A. 0\n B. 1\n C. 2\n D. 3
    text = "Please answer following question shortly.\n\nFind all c in Z_3 such that Z_3[x]\/(x^2 + c) is a field.\n\n A. 0\n B. 1\n C. 2\n D. 3"
    
    
    # å®Œæ•´åˆ†æï¼ˆç†µ + activation + logitsï¼‰
    tokens, entropies, all_acts, all_attn, logits = analyze_token_entropy(
        model, tokenizer, text, max_new_tokens=1024, 
        collect_activations=True
    )
    
    # å‡è®¾é€‰ä¸€ä¸ªattentionçŸ©é˜µ
    attn_key = "layer_20_head_20"#list(all_attn.keys())[0]
    attn_matrix = all_attn[attn_key]

    # è®¡ç®—åˆ†æ•°
    scores = compute_token_scores(
        tokens,
        entropies,
        all_acts,
        logits,
        attn_matrix,
        alpha=1.0, beta=1.0, delta=1.0
    )

    # å¯è§†åŒ–
    plot_token_scores(scores)